# O que √© a arquitetura de microsservi√ßos?

A arquitetura de microsservi√ßos pode ser comparada com a linha de produ√ß√£o utilizada em f√°bricas.

Nessa arquitetura, cada "servi√ßo" √© um peda√ßo de c√≥digo que executa uma tarefa.

# Full Cycle Developer

1. Operate what you build
  > Desde a concep√ß√£o at√© a entrega
2. Ferramentas para escalar
  > Dominar ferramentas que v√£o o ajudar a escalar seu deploy

## Full Cycle vs Full Stack

Um full stack √© uma pessoa que domina determinada stack, podendo programar tanto no back-end quanto no front-end.
Um full cycle √© uma pessoa que al√©m de desenvolver consegue testar, fazer o deploy e monitorar aplica√ß√µes. Al√©m disso, o full cycle domina processos que permitem que essas aplica√ß√µes **escalem**.

## Processo de desenvolvimento

# CodePix

- √â uma solu√ß√£o para simularmos transfer√™ncias de valores entre bancos fict√≠cios atrav√©s de chaves (email, cpf).
- Simularemos diversos bancos e contas banc√°rias que possuem uma chave Pix atribuida.
- Cada conta banc√°ria poder√° cadastrar suas chaves Pix.
- Uma conta banc√°ria poder√° realizar uma transfer√™ncia para outra conta em outro banco utilizando a chave Pix da conta de destino.
- Uma transa√ß√£o n√£o pode ser perdida mesmo que: o CodePix esteja fora do ar.
- Uma transa√ß√£o n√£o pode ser perdida mesmo que: o Banco de destino esteja fora do ar.

## Sobre os Bancos

- O banco ser√° um microsservi√ßo com fun√ß√µes limitadas a cadastro de contas e chaves Pix, bem como transfer√™ncia de valores.
- Utilizaremos a mesma aplica√ß√£o para simularmos diversos bancos, mudando apenas cores, nome e c√≥digo. (multi-tenant).
- Nest.js no back-end.
- Next.js no front-end.

## Sobre o CodePix

- O microsservi√ßo CodePix ser√° respons√°vel por intermediar as transfer√™ncias banc√°rias
- Receber√° a transa√ß√£o de transfer√™ncia
- Encaminhar√° a transa√ß√£o para o banco de destino (Status: "pending")
- Recebe a confirma√ß√£o do banco de destino (Status: "confirmed")
- Envia a confirma√ß√£o para o banco de origem informando quando o banco de destino processou
- Recebe a confirma√ß√£o do banco de origem de que ele processou (Status: "completed")
- Marca a transa√ß√£o como completa. (Status: "completed")

## Din√¢mica do Processo

![Din√¢mica](image.png)

## Principais desafios

- Comunica√ß√£o r√°pida e eficiente
- Cria√ß√£o e consulta instant√¢nea das chaves (S√≠ncrona)
- Garantia de que nenhuma transa√ß√£o seja perdida, mesmo que qualquqer dos 3 sistemas estejam fora (Ass√≠ncrona).

## CodePix

- Ser√° capaz de atuar como um servidor gRPC.
- Consumir e publicar mensagens no Apache Kafka.
- Ambas opera√ß√µes devem ser realizadas de forma simult√¢nea ao executar o servi√ßo.
- Trabalhar com um design focado em solucionar o problema do dom√≠nio (DDD).
- Deixar a complexidade t√©cnica para "camada de aplica√ß√£o", respons√°vel pelo servidor gRPC e Kafka.
- Flex√≠vel para implementa√ß√£o de outros formatos de comunica√ß√£o, como API Rest, CLI clients, etc. SEM alterar nenhum outro componente da aplica√ß√£o ou o modelo de dom√≠nio.

## Arquitetura de Software

Arquitetura √© essencial para evitar retrabalhos, adiciona "sustenta√ß√£o" ao c√≥digo e permite que voc√™ construa aplica√ß√µes de forma mais eficaz.

Caso voc√™ n√£o desenhe logo de cara como vai ser a arquitetura do seu software voc√™ pode transformar ele em uma *Tech Debt* que vai precisar ser paga em algum momento.

Pontos da arquitetura de software.

- Crescimento Sustent√°vel.
- Manuten√ß√£o.
- A complexidade inicial se paga ao longo do projeto.
- O seu software deve ser definido e desenhado por voc√™ e n√£o pelo seu framework.
- As pe√ßas tem que se encaixar, mas eventualmente podem ser substitu√≠das ou adicionadas.

## Arquitetura Hexagonal/Ports and Adapters

O mundo externo se conecta a nossa aplica√ß√£o por meio de portas que s√£o expostas pela aplica√ß√£o.
E a aplica√ß√£o se conecta a outras ferramentas via adaptadores.

## Estrutura e camadas do CodePix

- application
  > Respons√°vel por lidar com o c√≥digo por tr√°s da regra de neg√≥cio
  - factory
    > Inst√¢ncia de objetos com muitas depend√™ncias.
  - grpc
    > Servidor e servi√ßo disponibilizados via gRPC.
  - kafka
    > Consumo e processamento de transa√ß√µes com o Apache Kafka.
  - model
    > Modelagem dos dados que vem de diversas fontes.
  - usecase
    > Executa o fluxo da aplica√ß√£o de acordo com as regras de neg√≥cio.
- cmd
  > Respons√°vel por iniciar a aplica√ß√£o.
- domain
  > Cora√ß√£o da aplica√ß√£o e regras de neg√≥cios.
  - model
- infrastructure
  > Low-level, conex√£o com banco de dados.
  - db
    > Configura√ß√£o do ORM e a interface com o banco
  - repository
    > Uma estrutura que permite a persist√™ncia de dados, independente de ser em uma API, banco de dados ou arquivo .txt

    > Chamado pelos "usecases"

## Recursos a Serem Utilizados

- Docker
- Golang
- Apache Kafka


# Aula 1 - Servidor

Estou criando o projeto no reposit√≥rio [codepix](https://github.com/vitorgouveia/codepix).

Primeiramente foi criado o `Dockerfile` e o `docker-compose.yml`, eles permitem que eu execute toda a stack necess√°ria (Postgres, Kafka, Go) sem ter que instalar nada na minha m√°quina.

Depois, utilizei o comando `docker-compose up -d` para iniciar todos os containers das aplica√ß√µes, a partir da√≠, utilizei o comando `docker-compose ps` para listar todos os containers que estavam de p√© e copiei o nome do container "app".

Fiz isso para entrar no container via bash com o comando `docker exec -it codepix_app_1 bash`, isso me permitiu trabalhar na minha pasta local utilizando tecnologias que n√£o tinha instalado na minha m√°quina.ü§Ø

## Arquitetura

A programa√ß√£o iniciou na pasta model. L√°, guardamos todas as entidades da nossa aplica√ß√£o, junto das regras de neg√≥cio e interfaces para comunica√ß√£o com o banco de dados.

Eu vi na pr√°tica que arquitetura de software √© algo al√©m do c√≥digo, j√° que me vejo f√°cilmente implementando aquele mesmo c√≥digo por√©m em Javascript ou Typescript. Inclusive pretendo fazer uma vers√£o 2 desse projeto por√©m com javascript.

### Models

O interessante √© que todos os models tem um m√©todo chamado `isValid()` que verifica as regras de valida√ß√£o dos campos e retorna uma exce√ß√£o sempre que encontrar um erro.

Esse m√©todo √© chamado na inicializa√ß√£o da Entidade, ou seja, toda vez que √© inst√¢nciada ela automaticamente verifica se seus campos s√£o v√°lidos, o que √© cr√≠tico para o funcionamento da aplica√ß√£o, j√° que estamos lidando com o cru das regras de neg√≥cio.

# Aula 2 - gRPC

gRPC √© um framework criado pela Google que tem o objetivo de facilitar o processo de comunica√ß√£o entre sistemas de uma forma extremamente r√°pida.

- Ideal para microsservi√ßos
- Mobile, Browsers e Backend
- Gera√ß√£o das bibliotecas de forma autom√°tica
- Streaming bidirecional utilizando HTTP/2

As linguagens que tem suporte oficial para gRPC s√£o go, java, C (por√©m todas as linguagens se comunicam com C, ent√£o tem suporte para basicamente todas as linguagens).

## RPC (Remote Procedure Call)

Quando um cliente executa uma fun√ß√£o do servidor.

## Protocol Buffers

*Protoco Buffers* √© um mecanismo agn√≥stico de linguagem e plataforma, criado pela Google para serializar dados estruturados.

```
syntax = "proto3";

message SearchRequest {
  string query = 1;
  int32 page_number = 2;
  int32 results_per_page = 3;
}
```

## Protocol Buffers vs JSON

- Protocol Buffers tr√°fega os dados em formato bin√°rio, enquanto JSON usa texto.
- Serializar Protocol Buffers √© mais r√°pido
- Gasta menos recursos de rede

## HTTP/2

- Dados s√£o tr√°fegados em bin√°rio.

## Arquitetura

Nessa aula foi montada toda a estrutura de relacionamento do dom√≠nio da aplica√ß√£o com o banco de dados e servidor gRPC.

Seguindo o SOLID, foram criados reposit√≥rios e use-cases, que s√£o independentes de si e dependem de implementa√ß√µes desses contratos apenas.

Novamente, a arquitetura √© muito importante, cada pasta tem seu funcionamento √∫nico:

- application
  > Respons√°vel por lidar com o c√≥digo por tr√°s da regra de neg√≥cio
  - grpc
    > Servidor e servi√ßo disponibilizados via gRPC.
  - usecase
    > Executa o fluxo da aplica√ß√£o de acordo com as regras de neg√≥cio.
- cmd
  > Respons√°vel por iniciar a aplica√ß√£o e CLI.
- domain
  > Cora√ß√£o da aplica√ß√£o e regras de neg√≥cios.
  - model
    > Modelos da aplica√ß√£o que implementam as regras de neg√≥cio
- infrastructure
  > Low-level, conex√£o com banco de dados.
  - db
    > Configura√ß√£o do ORM e a interface com o banco
  - repository
    > Uma estrutura que permite a persist√™ncia de dados, independente de ser em uma API, banco de dados ou arquivo .txt

    > Chamado pelos "usecases"

# Aula 3 - Kafka.js

## Dupla Lat√™ncia

Fen√¥meno que acontece com arquitetura de microsservi√ßos, onde para enviar uma resposta para o cliente √© necess√°rio chamar multiplos microsservi√ßos, e isso pode acarretar em uma resposta mais demorada que o esperado.

## Kafka

√â uma ferramenta para persist√™ncia de dados entre microsservi√ßos, mitigando a perda de dados.

### Conceito B√°sico

#### Topic

- Stream de dados que atua como um banco de dados
- Cada t√≥pico tem um local para armazenar seus dados
- T√≥pico possui diversas parti√ß√µes
  - Cada parti√ß√£o √© definida por n√∫mero. Ex: 0, 1, 2.
  - Voc√™ √© obrigado a definir o n√∫mero de parti√ß√µes quando for criar um t√≥pico.

#### Producer & Consumer

- Producer produz os eventos
- Consumer consome os eventos

#### Kafka Cluster

- Conjunto de Brokers
- Cada Broker √© um server
- Cada Broker √© respons√°vel por armazenar dados de uma parti√ß√£o
- Cada Topic est√° distribuido em diferentes brokers

Distribui√ß√£o de Clusters Kafka

![Alt text](image-1.png)

A replica√ß√£o do Kafka faz c√≥pias da mesma parti√ß√£o de um t√≥pico em v√°rios brokers, para garantir que nenhuma mensagem seja perdida.

![Alt text](image-2.png)

#### Ecossistema

- Kafka Connect
  - Connectors
- Confluent Schema Registry

## Factories

S√£o fun√ß√µes utilizadas para gerar depend√™ncias da aplica√ß√£o (reposit√≥rios, use-cases).

## DTO

Transformam seu *input* de dados vindo do Kafka/gRPC/REST no formato de entidades da sua aplica√ß√£o.

## Worker Threads

Utilizei as worker threads do Node.js para executar o servidor gRPC e Kafka de forma simult√¢nea. Assim, cada um executa em uma thread.

## Inicializando a Aplica√ß√£o

```bash
docker-compose down

docker-compose up -d --build

docker exec -it codepix_app_1 bash

npm run start all
```

# Aula 4 - Nest.js

Nessa aula vamos desenvolver a aplica√ß√£o dos bancos, que v√£o utilizar das tecnologias:

- Nest.js (Back-end)
- Next.js (BFF & Front)
- Typescript
- PostgreSQL

## Arquitetura

![](image-3.png)

## Kafka

O servidor kafka, o *control center* e o zookeeper est√£o agora centralizados em uma pasta `kafka`, em um docker-compose separado.

Para incializar, basta executar o seguinte comando:

```bash
docker-compose down

docker-compose up -d --build
```

## Arquitetura de Microsservi√ßos

A comunica√ß√£o tanto via gRPC e Kafka funcionou perfeitamente e √© bonito ver os servi√ßos se comunicando dessa forma.

## Nest.js

O Nest.js possui muito boilerplate, um modelo repetitivo de fazer as coisas, por√©m isso gera previsibilidade no c√≥digo e permite a constru√ß√£o de aplica√ß√µes padronizadas. O que √© perfeito para trabalhar em equipes.

Foi muito f√°cil implementar a comunica√ß√£o gRPC e Kakfa no Nest.js.

## Como inicalizar o Nest.js no Docker

```bash
docker-compose down

docker-compose up -d --build

docker exec -it -u root server_app_1 bash

BANK_CODE=001 npm run console fixtures
BANK_CODE=001 npm run start:dev
```

# Aula 5 - Next.js

Vamos utilizar o Next.js para desenvolver o front-end dos bancos.

Esse front-end vai utilizar de SSR (*Server Side Rendering*) com a nova arquitetura de rotas do Next.js com Server e Client components para entregar o HTML pronto com os dados pra o front-end.

Vamos tamb√©m criar uma estrutura BFF no *Server-side* do Next.js para facilitar o acesso as APIs do Nest.js. Esse BFF vai utilizar das novas tecnologias mais recentes de cache do next.js para permitir um carregamento ainda mais r√°pido aplica√ß√£o.

## Queries reutiliz√°veis

O c√≥digo abaixo foi utilizado na Navbar e outros componentes da aplica√ß√£o, isso porque, o *server-side* + cache do next.js permite que n√≥s salvemos queries como essa para reutilizar em outras partes do c√≥digo sem se preocupar com o cache ou state do React.

```js
import { BankAccount } from '@/models';

export const getBankAccount = async (id: string): Promise<BankAccount> => {
  const response = await fetch(
    `${process.env.NEXT_PUBLIC_API_URL}/bank-accounts/${id}`,
    {
      next: { revalidate: 20, tags: [`bank-accounts/${id}`] },
    },
  );

  return response.json();
};
```

## Client Side

Pouqu√≠ssimos componentes foram renderizados do lado do cliente, dessa forma, o bundle de javascript enviado para o navegador √© min√∫sculo, carregando a aplica√ß√£o *ainda* mais r√°pido.

<!-- # Aula 6 - DevOps

## Kubernetes

Kubernetes (K8s) √© um gerenciador de aplica√ß√µes de containers.

- Disponibilizado atrav√©s de um conjunto de APIs.
  > Todas as funcionalidades Kubernetes s√£o acessadas por APIs
- kubectl √© a CLI para acessar essas APIs por√©m via linha de comando.
- Kubernetes Master

### Cluster

Cluster √© um conjunto de m√°quinas (nodes).
Cada m√°quina possui um n√∫mero de recursos (vCpu, Ram).

### Pod

Pod possui um ou mais containers rodando a aplica√ß√£o.

### Deployment

![Alt text](image-4.png)

## Dockerfile

Foi gerada uma dockerfile nova para todos os servi√ßos, chamada de `Dockerfile.prod`, essa dockerfile vai executar o comando de produ√ß√£o de cada servi√ßo.

Ap√≥s isso, deve ser gerada uma imagem da dockerfile de cada servi√ßo

```bash
docker build -t vitorgouveia1/codepix:latest -f Dockerfile.prod
```

E ent√£o, essas imagens devem ser enviadas para o dockerhub com o comando:

```bash
docker push vitorgouveia1/codepix:latest
```

## Kubernetes

Existem diversas formas de utilizar o Kubernetes em produ√ß√£o, como no Google Cloud Platform, Azure, AWS, Digital Ocean.

Por√©m, utilizarei local utilizando a ferramenta chamada [kind](https://kind.sigs.k8s.io)

Ele consegue rodar o kubernetes dentro de containers docker de forma local.

### Executando Local

Agora devemos iniciar a cria√ß√£o de um cluster para testar a aplica√ß√£o.

```
kind create cluster --name=codepix 
```

> O kind ir√° criar um cluster com apenas 1 node.

Ap√≥s isso, devemos "avisar" o kubectl que iremos trabalhar com esse cluster, para isso ent√£o, rode o comando:

```bash
kubectl cluster-info --context kind-codepix
```

Agora, tudo que for rodado via `kubectl` ser√° dentro desse contexto do codepix.

Para ver isso em a√ß√£o, liste os nodes utilizando

```
kubectl get nodes
```

---

Ap√≥s todo esse *setup* inicial devemos criar os arquivos de configura√ß√£o para iniciar um pod no k8s.

Para isso foram criados os arquivos `deploy.yaml`, contendo regras de funcionamento do pod e o `configmap.yaml` contendo vari√°veis de ambiente.

Com esses arquivos preenchidos, √© poss√≠vel rodar alguns comandos e subir nosso primeiro pod.

```bash
kubectl apply -f configmap.yml
kubectl apply -f deploy.yml

kubectl get pods # Lista 
```

### Comandos √öteis

```bash
kubectl get pods # Lista todos os pods.
kubectl logs <pod> # Lista os logs de dentro do pod.
kubectl describe pod <pod> # Lista os passos percorridos pelo k8s na constru√ß√£o do pod.
```
-->